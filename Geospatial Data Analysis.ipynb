{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c674060",
   "metadata": {},
   "source": [
    "# Geospatial Analysis Primer\n",
    "\n",
    "In this workbook, we'll look at how we can utilize Python to conveniently process and make predictions on geospatial data. We'll show how three separate datasets can be combined to investigate the relationship between 311 calls in Toronto and the rates of short-term rentals.\n",
    "\n",
    "Learning Objectives:\n",
    "- Understand how to load and manipulate geospatial data using Python libraries.\n",
    "- Spatially join datasets to analyze relationships.\n",
    "- Model the relationship between 311 calls and short-term rentals.\n",
    "- Visualize the results of the analysis.\n",
    "\n",
    "## Setup\n",
    "\n",
    "For this workbook, we will primarily rely on the GeoPandas library for geospatial data manipulation, along with Folium for visualization and Scikit-learn for modeling. Make sure you have these libraries installed in your Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopandas folium scikit-learn interpret jupyter ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433632b",
   "metadata": {},
   "source": [
    "We will be working with three datasets from the Toronto Open Data portal: \n",
    "\n",
    "1. **Toronto Wards**: A dataset containing the boundaries of Toronto's wards, which will help us understand the spatial distribution of data.\n",
    "2. **311 Service Requests**: A dataset of 311 service requests in Toronto, which includes the location of each request.\n",
    "3. **Short-Term Rentals**: A dataset of short-term rental listings in Toronto, which includes the location of each listing.\n",
    "\n",
    "Our first task is to load these datasets into our Python environment. The Toronto Open Data portal is built on CKAN, which provides a convenient API for accessing datasets. We will use the `requests` library to fetch the data and `pandas` to read it into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6458b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca/api/3/action/package_show\"\n",
    "datasets = [\"city-wards\", \"311-service-requests-customer-initiated\", \"short-term-rentals-registration\"]\n",
    "resource_number = [11, 1, 1]  # Resource ID for each dataset\n",
    "file_type = [\"geojson\", \"zip\", \"csv\"]  # Expected file types for each dataset\n",
    "\n",
    "for dataset, res_num, f_type in zip(datasets, resource_number, file_type):\n",
    "    response = requests.get(base_url, params={\"id\": dataset}).json()\n",
    "    resource = response['result']['resources'][res_num]\n",
    "    print(f\"Dataset: {dataset}, Resource: {resource['url']}\")\n",
    "\n",
    "    # Download the data\n",
    "    data_response = requests.get(resource['url'])\n",
    "    with open(f\"{dataset}.{f_type}\", \"wb\") as file:\n",
    "        file.write(data_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a015b80",
   "metadata": {},
   "source": [
    "Now that we've downloaded our three datasets, we can load them into our Python environment. We'll use the `geopandas` library to handle the geospatial data and `pandas` for the tabular data. We'll start by loading the 311 service requests dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0326562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "service_requests = pd.read_csv(\"311-service-requests-customer-initiated.zip\", compression='zip', on_bad_lines='skip', low_memory=False)\n",
    "to_keep = [\"Ward\", \"Service Request Type\", \"Division\", \"Section\", \"First 3 Chars of Postal Code\"]\n",
    "service_requests = service_requests[to_keep]\n",
    "# Split the \"Ward\" column into \"Ward Number\" and \"Ward Name\". Format is Ward Name (Number). There are non-alphabet characters in the ward name, e.g. Toronto-St. Paul's (12)\n",
    "service_requests[['Ward Name', 'Ward Number']] = service_requests['Ward'].str.extract(r'([^\\d]+)\\s*\\((\\d+)\\)')\n",
    "# Drop the original \"Ward\" column and any rows with missing values in \"Ward Name\" or \"Ward Number\"\n",
    "service_requests = service_requests.drop(columns=['Ward']).dropna(subset=['Ward Name', 'Ward Number'])\n",
    "# Convert \"Ward Number\" to integer type\n",
    "service_requests['Ward Number'] = service_requests['Ward Number'].astype(int)\n",
    "service_requests.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e5780",
   "metadata": {},
   "source": [
    "We had to do some cleaning there to prepare the data for us. Namely, we split the single \"Ward\" column, with entries like \"Toronto-St. Paul's (12)\" into two separate columns: \"Ward Number\" and \"Ward Name\". We also dropped any rows that weren't super relevant to our analysis, such as those without a ward number or name, and dropped columns that we didn't need for our analysis.\n",
    "\n",
    "Next, we can load the rental data. Similarly, we will clean it up by keeping only the relevant columns and renaming them for consistency. We will also ensure that the \"Ward Number\" is in the correct format for merging with the 311 service requests data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaf489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals = pd.read_csv(\"short-term-rentals-registration.csv\" , on_bad_lines='skip', low_memory=False)\n",
    "to_keep = [\"property_type\", \"ward_number\", \"ward_name\", \"postal_code\"]\n",
    "rentals = rentals[to_keep]\n",
    "rentals = rentals.rename(columns={\"ward_number\": \"Ward Number\", \"ward_name\": \"Ward Name\", \"postal_code\": \"First 3 Chars of Postal Code\"})\n",
    "rentals['Ward Number'] = rentals['Ward Number'].astype(int)\n",
    "rentals = rentals.dropna(subset=['Ward Name', 'Ward Number'])\n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3325c",
   "metadata": {},
   "source": [
    "Lastly, we will load the Toronto wards data. This dataset contains the geographical boundaries of each ward, which will allow us to spatially join it with the 311 service requests and short-term rentals data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a4710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wards = gpd.read_file(\"city-wards.geojson\")\n",
    "to_keep = [\"AREA_SHORT_CODE\", \"AREA_NAME\", \"geometry\"]\n",
    "wards = wards[to_keep]\n",
    "wards = wards.rename(columns={\"AREA_SHORT_CODE\": \"Ward Number\", \"AREA_NAME\": \"Ward Name\"})\n",
    "wards['Ward Number'] = wards['Ward Number'].astype(int)\n",
    "wards = wards.dropna(subset=['Ward Name', 'Ward Number'])\n",
    "wards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f63b07",
   "metadata": {},
   "source": [
    "GeoPandas not only lets us access the data in a tabular way as if it's a standard Pandas DataFrame, but it also allows us to quickly visualize the data on a map, and perform spatial operations like joins and intersections. Let's visualize the wards to make sure they look how we'd expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Basic plot of the wards with no background map\n",
    "wards.plot(figsize=(10, 10), edgecolor='black', alpha=0.5)\n",
    "\n",
    "# Write ward numbers on top of each ward\n",
    "for x, y, label in zip(wards.geometry.centroid.x, wards.geometry.centroid.y, wards['Ward Number']):\n",
    "    plt.text(x, y, label, fontsize=12, ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1aa994",
   "metadata": {},
   "source": [
    "Further along in the process, we'll use `Folium` to produce interactive maps that let us visualize the data in a more user-friendly way. This will allow us to see the distribution of 311 service requests and short-term rentals across the wards of Toronto. For now, though, just seeing the basic plot from GeoPandas is a good start to ensure our data is loaded correctly.\n",
    "\n",
    "## Combining Datasets\n",
    "\n",
    "Now that we have our three datasets loaded and cleaned, we can proceed to combine them. The goal is to analyze the relationship between 311 service requests and short-term rentals across the wards of Toronto.\n",
    "\n",
    "Initially, we'll do this by joining on the ward number. This will allow us to aggregate the 311 service requests and short-term rentals by ward, enabling us to analyze the relationship between these two datasets.\n",
    "\n",
    "### Aggregate 311 by Service Request Type\n",
    "\n",
    "To aggregate our service requests, we'll group our DataFrame by both Ward Number and Service Request Type. This will tell us how many service requests of each type were made in each ward. Then, we use the `.size()` method to count the number of requests for each type in each ward, which we'll ultimately be combining with the short-term rentals data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f917bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_311 = (\n",
    "    service_requests\n",
    "    .groupby(['Ward Number', 'Service Request Type'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .add_prefix('311_')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg_311.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb10b6",
   "metadata": {},
   "source": [
    "### Aggregate STR count by Property Type\n",
    "\n",
    "Next, we'll apply a similar logic to our short-term rentals data. We'll group by Ward Number and Property Type to get the count of each type of rental in each ward. This will give us a clearer picture of the distribution of short-term rentals across the wards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e321f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_str = (\n",
    "    rentals\n",
    "    .groupby(['Ward Number', 'property_type'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .add_prefix('STR_')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg_str.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3daf3",
   "metadata": {},
   "source": [
    "Now that we have our aggregate data for each ward, we can merge into the wards GeoDataFrame. This will allow us to visualize the data on a map and perform further analysis.\n",
    "\n",
    "You'll note that we supply the `on` and `how` parameters to the `merge` function. The `on` parameter specifies the column to join on, which in this case is \"Ward Number\". The `how` parameter specifies the type of join to perform; we use 'left' to keep all wards even if they don't have any service requests or short-term rentals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0aff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_combined = wards.merge(agg_311, on='Ward Number', how='left').merge(agg_str, on='Ward Number', how='left')\n",
    "\n",
    "gdf_combined = gdf_combined.fillna(0)  # Fill NaN values with 0 for better visualization\n",
    "\n",
    "gdf_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f36a0",
   "metadata": {},
   "source": [
    "We can now trivially plot values for any given column in our combined GeoDataFrame. For example, below we'll plot the number of `311_Complaint - Crossing Guard Conduct` requests in each ward. This will give us a visual representation of where these types of service requests are concentrated across the wards of Toronto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_combined.plot(column='311_Complaint - Crossing Guard Conduct', figsize=(10, 10), legend=True, cmap='OrRd', edgecolor='black')\n",
    "plt.title('311 Complaints - Crossing Guard Conduct by Ward')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251aae0d",
   "metadata": {},
   "source": [
    "For more interactive and frankly better looking maps, we can turn to the `Folium` library. Folium allows us to create interactive maps that can be embedded in Jupyter notebooks or saved as HTML files. This is particularly useful for visualizing geospatial data, as it provides a more user-friendly interface for exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff59a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import branca.colormap as cm\n",
    "\n",
    "# 1) Build a colour scale based on STR_Apartment range\n",
    "vmin, vmax = gdf_combined[\"STR_Apartment\"].min(), gdf_combined[\"STR_Apartment\"].max()\n",
    "colormap = cm.linear.OrRd_09.scale(vmin, vmax)        # orange-red gradient\n",
    "colormap.caption = \"Short-term-rental apartments (count)\"\n",
    "\n",
    "# 2) Start the base map centred on Toronto\n",
    "m = folium.Map(location=[43.7000, -79.4200], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "# 3) Add polygons with ward-level styling + hover tool-tip\n",
    "folium.GeoJson(\n",
    "    gdf_combined,\n",
    "    name=\"STR Apartments\",\n",
    "    style_function=lambda feat: {\n",
    "        \"fillColor\": colormap(feat[\"properties\"][\"STR_Apartment\"])\n",
    "                     if feat[\"properties\"][\"STR_Apartment\"] is not None else \"#d3d3d3\",\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.8,\n",
    "        \"fillOpacity\": 0.7,\n",
    "    },\n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=[\"Ward Name\", \"STR_Apartment\"],\n",
    "        aliases=[\"Ward\", \"STR apartments\"],\n",
    "        localize=True\n",
    "    ),\n",
    ").add_to(m)\n",
    "\n",
    "# 4) Add legend + layer control\n",
    "colormap.add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# 5) Save and/or display\n",
    "m.save(\"toronto_str_apartments_map.html\")\n",
    "m          # in-notebook display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4500e",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "Now, let's use the combined dataset to model the relationship between 311 service requests and short-term rentals. We'll use a Random Forest Regressor from the scikit-learn library to predict the number of 311 service requests (by type) based on the number of short-term rentals in each ward. Then, we can examine to see if any of the short-term rental types are significant predictors of the number of 311 service requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "############################################################\n",
    "# 1. Feature / target matrices\n",
    "############################################################\n",
    "# Keep only numeric, non-geometry columns\n",
    "numeric_df = gdf_combined.drop(columns=\"geometry\")\n",
    "\n",
    "# Predictor columns  = all STR_* variables\n",
    "str_cols = [c for c in numeric_df.columns if c.startswith(\"STR_\")]\n",
    "X = numeric_df[str_cols]\n",
    "\n",
    "# Target columns     = all 311_* variables\n",
    "target_cols = [c for c in numeric_df.columns if c.startswith(\"311_\")]\n",
    "\n",
    "print(f\"Predictor columns: {X.columns.tolist()}\")\n",
    "print(f\"Target columns: {target_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 2. Hyper-parameters for the forest - change if running slowly\n",
    "############################################################\n",
    "rf_params = dict(\n",
    "    n_estimators=500, # Reduce to 100 if running slowly\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 3. Fit one Random Forest per 311 category\n",
    "############################################################\n",
    "results = []          # will collect performance metrics\n",
    "importances = []      # will collect feature importance per model\n",
    "\n",
    "for target in tqdm(target_cols, desc=\"Fitting models\", unit=\"model\"):\n",
    "    y = numeric_df[target]\n",
    "\n",
    "    # Split ward rows 80/20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict → test metrics\n",
    "    y_pred = rf.predict(X_test)\n",
    "    r2   = r2_score(y_test, y_pred)\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Store overall metrics\n",
    "    results.append({\"311_type\": target, \"R2_test\": r2, \"RMSE_test\": rmse})\n",
    "\n",
    "    # Store and label feature importances\n",
    "    imp = pd.Series(rf.feature_importances_, index=X.columns, name=target)\n",
    "    importances.append(imp.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 4. Show summary table\n",
    "############################################################\n",
    "results_df = pd.DataFrame(results).sort_values(\"R2_test\", ascending=False)\n",
    "\n",
    "# Display columns where R2_test is greater than 0.75\n",
    "display(results_df[results_df[\"R2_test\"] > 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb6ade",
   "metadata": {},
   "source": [
    "Now that our models are complete, we can see there are approximately 90 service request types where the R2 score is greater than 0.5, indicating a strong relationship between the number of short-term rentals and the number of service requests.\n",
    "\n",
    "We can further investigate whether there is a specific relationship between type of short-term rental and the types of service requests made. Let's utilize the interpret library to build a **Glass Box** model. This is a model that allows us to see the feature importances and understand how each feature contributes to the predictions.\n",
    "\n",
    "We'll focus on the `311_Litter / Bike Removal Inquiry` service request, which has a high R2 of around 0.975. This indicates a strong relationship between the number of short-term rentals and the number of litter/bike removal inquiries in each ward. Let's see if that holds up under greater scrutiny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc65152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "y = numeric_df[\"311_Litter / Bike Removal Inquiry\"]\n",
    "X = numeric_df[str_cols]\n",
    "\n",
    "ebm = ExplainableBoostingRegressor(random_state=42)\n",
    "ebm.fit(X, y)\n",
    "show(ebm.explain_global(name=\"311_Litter / Bike Removal Inquiry\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4095674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ebm.explain_local(X, y, name=\"311_Litter / Bike Removal Inquiry\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93be132",
   "metadata": {},
   "source": [
    "## Extension: Postal-Code Level Analysis\n",
    "\n",
    "Our two tabular datasets also contain the first three letters of the postal code for each service request and short-term rental. This means we can also aggregate our data at the postal code level, which will give us a more granular view of the relationship between short-term rentals and 311 service requests.\n",
    "\n",
    "Download the FSA dataset below from Statistics Canada to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "fsa_boundaries_url = \"https://www12.statcan.gc.ca/census-recensement/2021/geo/sip-pis/boundary-limites/files-fichiers/lfsa000a21a_e.zip\"\n",
    "\n",
    "response = requests.get(fsa_boundaries_url)\n",
    "with open(\"fsa_boundaries.zip\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "with zipfile.ZipFile(\"fsa_boundaries.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "\n",
    "fsa_boundaries = gpd.read_file(\"lfsa000a21a_e/lfsa000a21a_e.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc731dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa_boundaries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731564e2",
   "metadata": {},
   "source": [
    "We only need the FSAs that could be present in Toronto, so we can begin by filtering down to that. We can check if the \"PRNAME\" field contains \"Ontario\" and the \"FSA\" field starts with \"M\", which is the prefix for Toronto postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5007d61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa_boundaries = fsa_boundaries[fsa_boundaries[\"PRNAME\"].str.contains(\"Ontario\") & fsa_boundaries[\"CFSAUID\"].str.startswith(\"M\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa_boundaries.plot(figsize=(10, 10), edgecolor='black', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f8614",
   "metadata": {},
   "source": [
    "Great, that looks like Toronto! Now we can break down our data by FSA instead of by the larger wards. This will allow us to see the distribution of 311 service requests and short-term rentals at a more granular level.\n",
    "\n",
    "Our data directly tells us how many service requests and short-term rentals there are in each FSA, so we can easily aggregate our data by FSA. We can then merge this aggregated data with the FSA boundaries to visualize the data on a map. Let's imagine, though, that we don't have this data and we only have the ward-level information. We can still disaggregate our data by FSA and get an approximation of the number of service requests and short-term rentals in each FSA. Let's explore how we might do that.\n",
    "\n",
    "### 1. Prep\n",
    "\n",
    "We first need to quickly make sure that both layers share the same CRS (Coordinate Reference System). This is important for spatial operations like joins and intersections. We can use the `to_crs` method to convert the FSA boundaries to the same CRS as our combined GeoDataFrame.\n",
    "\n",
    "### 2. Ward x FSA intersection + area fractions\n",
    "\n",
    "Now that we have both layers in the same CRS, we can perform a spatial join to find the intersection between the wards and FSAs. This will allow us to calculate the area of each intersection, which we can then use to determine the fraction of each ward that falls within each FSA.\n",
    "\n",
    "### 3. Apportioning service requests and short-term rentals\n",
    "With the area fractions calculated, we can now apportion the service requests and short-term rentals from the ward level to the FSA level. This will give us a more granular view of the relationship between short-term rentals and 311 service requests at the postal code level.\n",
    "\n",
    "### 4. Aggregation to FSA level\n",
    "Finally, we can aggregate the data by FSA to get the total number of service requests and short-term rentals in each FSA. This will allow us to analyze the relationship between short-term rentals and 311 service requests at a more granular level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# 1. Prep – make sure both layers share the same CRS\n",
    "# ----------------------------------------------------------\n",
    "fsa_boundaries = fsa_boundaries.to_crs(gdf_combined.crs)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Ward x FSA intersection\n",
    "# ----------------------------------------------------------\n",
    "ward_fsa = gpd.overlay(gdf_combined, fsa_boundaries, how=\"intersection\")\n",
    "\n",
    "# Area of each overlap polygon\n",
    "ward_fsa[\"area_overlap\"] = ward_fsa.geometry.area\n",
    "\n",
    "ward_area = (\n",
    "    gdf_combined\n",
    "      .assign(ward_area=gdf_combined.geometry.area)\n",
    "      .loc[:, [\"Ward Number\", \"ward_area\"]]       \n",
    ")\n",
    "\n",
    "ward_fsa = ward_fsa.merge(ward_area, on=\"Ward Number\", how=\"left\")\n",
    "ward_fsa[\"area_frac\"] = ward_fsa[\"area_overlap\"] / ward_fsa[\"ward_area\"]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Vectorised apportioning\n",
    "# ----------------------------------------------------------\n",
    "numeric_cols = [\n",
    "    c for c in gdf_combined.columns\n",
    "    if c.startswith(\"311_\") or c.startswith(\"STR_\")\n",
    "]\n",
    "\n",
    "apportioned = (\n",
    "    ward_fsa[numeric_cols]\n",
    "        .mul(ward_fsa[\"area_frac\"], axis=0)   # scale by fraction\n",
    "        .add_suffix(\"_apportioned\")           # rename once\n",
    ")\n",
    "\n",
    "ward_fsa = pd.concat(\n",
    "    [ward_fsa[[\"CFSAUID\", \"geometry\"]], apportioned],\n",
    "    axis=1,\n",
    "    copy=False\n",
    ")\n",
    "\n",
    "    \n",
    "# ----------------------------------------------------------\n",
    "# 4. Aggregate to FSAs\n",
    "# ----------------------------------------------------------\n",
    "fsa_aggregated = (\n",
    "    ward_fsa\n",
    "      .drop(columns=\"geometry\")\n",
    "      .groupby(\"CFSAUID\")\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "fsa_map = (\n",
    "    fsa_boundaries\n",
    "      .merge(fsa_aggregated, on=\"CFSAUID\", how=\"left\")\n",
    "      .fillna(0)\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5. Quick Folium choropleth (example: STR apartments)\n",
    "# ----------------------------------------------------------\n",
    "column = \"STR_Apartment_apportioned\"\n",
    "\n",
    "vmin, vmax = fsa_map[column].min(), fsa_map[column].max()\n",
    "cmap = cm.linear.OrRd_09.scale(vmin, vmax).to_step(n=6)\n",
    "cmap.caption = \"Estimated STR Apartments (area-weighted)\"\n",
    "\n",
    "m = folium.Map(location=[43.7000, -79.4200], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "\n",
    "folium.GeoJson(\n",
    "    fsa_map,\n",
    "    name=\"STR Apartments (FSA)\",\n",
    "    style_function=lambda feat: {\n",
    "        \"fillColor\": cmap(feat[\"properties\"][column]),\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.5,\n",
    "        \"fillOpacity\": 0.7,\n",
    "    },\n",
    "    tooltip=folium.GeoJsonTooltip(\n",
    "        fields=[\"CFSAUID\", column],\n",
    "        aliases=[\"FSA\", \"Est. STR apartments\"],\n",
    "        localize=True,\n",
    "    ),\n",
    ").add_to(m)\n",
    "\n",
    "cmap.add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m.save(\"fsa_str_apportioned_map.html\")\n",
    "m  # shows the map inline in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77e357",
   "metadata": {},
   "source": [
    "Let's examine how this compares to the real data we have for the FSAs. We can aggregate our original data to the FSA level and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c30f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_311 = (\n",
    "    service_requests\n",
    "    .groupby(['First 3 Chars of Postal Code', 'Service Request Type'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .add_prefix('311_')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Drop the entry where First 3 Chars of Postal Code is \"Intersection\"\n",
    "agg_311 = agg_311[agg_311['First 3 Chars of Postal Code'] != 'Intersection']\n",
    "\n",
    "agg_311.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b998d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_str = (\n",
    "    rentals\n",
    "    .groupby(['First 3 Chars of Postal Code', 'property_type'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .add_prefix('STR_')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "agg_str.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename First 3 Chars of Postal Code to CFSAUID\n",
    "agg_311 = agg_311.rename(columns={\"First 3 Chars of Postal Code\": \"CFSAUID\"})\n",
    "agg_str = agg_str.rename(columns={\"First 3 Chars of Postal Code\": \"CFSAUID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccfc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 311 and STR dataframes on CFSAUID with fsa_boundaries\n",
    "gdf_fsa = fsa_boundaries.merge(agg_311, on=\"CFSAUID\", how=\"left\").merge(agg_str, on=\"CFSAUID\", how=\"left\")\n",
    "\n",
    "# Fill NaN values with 0 for better visualization\n",
    "gdf_fsa = gdf_fsa.fillna(0)\n",
    "\n",
    "# Plot STR_Apartment with Folium\n",
    "\n",
    "vmin, vmax = gdf_fsa[\"STR_Apartment\"].min(), gdf_fsa[\"STR_Apartment\"].max()\n",
    "colormap = cm.linear.OrRd_09.scale(vmin, vmax)        # orange-red gradient\n",
    "colormap.caption = \"Short-term-rental apartments (count)\"  \n",
    "# Start the base map centred on Toronto\n",
    "m_fsa = folium.Map(location=[43.7000, -79.4200], zoom_start=11, tiles=\"cartodbpositron\")\n",
    "# Add polygons with FSA-level styling + hover tool-tip\n",
    "folium.GeoJson(\n",
    "    gdf_fsa,\n",
    "    name=\"STR Apartments\",\n",
    "    style_function=lambda feat: {\n",
    "        \"fillColor\": colormap(feat[\"properties\"][\"STR_Apartment\"])\n",
    "                     if feat[\"properties\"][\"STR_Apartment\"] is not None else \"#d3d3d3\",\n",
    "        \"color\": \"black\",\n",
    "        \"weight\": 0.8,\n",
    "        \"fillOpacity\": 0.7,\n",
    "    },\n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=[\"CFSAUID\", \"STR_Apartment\"],\n",
    "        aliases=[\"FSA\", \"STR apartments\"],\n",
    "        localize=True\n",
    "    ),\n",
    ").add_to(m_fsa)\n",
    "# Add legend + layer control\n",
    "colormap.add_to(m_fsa)\n",
    "folium.LayerControl().add_to(m_fsa)\n",
    "# Save and/or display\n",
    "m_fsa.save(\"toronto_fsa_str_apartments_map.html\")\n",
    "m_fsa          # in-notebook display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "social",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
